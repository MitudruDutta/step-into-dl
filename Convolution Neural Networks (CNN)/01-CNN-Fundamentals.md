# ğŸ–¼ï¸ CNN Fundamentals

## What is a Convolutional Neural Network?

A **Convolutional Neural Network (CNN)** is a specialized type of neural network designed to process data with a grid-like topology, such as images. Unlike traditional fully connected networks that treat input as a flat vector, CNNs preserve and exploit the spatial structure of the data.

CNNs were inspired by the visual cortex of animals, where neurons respond to stimuli only in a restricted region of the visual field known as the receptive field.

---

## Why CNNs for Images?

### The Problem with Fully Connected Networks

Consider a simple 28Ã—28 grayscale image (like MNIST digits):

```
Fully Connected Approach:
  Input: 28 Ã— 28 = 784 pixels
  First hidden layer (256 neurons): 784 Ã— 256 = 200,704 parameters
  
  For a 224Ã—224 RGB image:
  Input: 224 Ã— 224 Ã— 3 = 150,528 pixels
  First hidden layer (256 neurons): 150,528 Ã— 256 = 38,535,168 parameters!
```

This approach has three major problems:

1. **Parameter Explosion**: The number of weights grows rapidly with image size
2. **Loss of Spatial Information**: Flattening destroys the 2D structure
3. **No Translation Invariance**: A cat in the corner looks completely different from a cat in the center

### How CNNs Solve These Problems

| Problem | CNN Solution |
|---------|--------------|
| Too many parameters | **Parameter sharing** â€” same filter applied across entire image |
| Lost spatial info | **Local connectivity** â€” neurons connect only to nearby pixels |
| No translation invariance | **Convolution operation** â€” detects features regardless of position |

---

## The Convolution Operation

The core of CNNs is the **convolution operation**, which slides a small filter (kernel) across the input image to produce a feature map.

### How Convolution Works

```
Input Image (5Ã—5)          Filter (3Ã—3)         Output (3Ã—3)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1  2  3  4  5   â”‚        â”‚ 1  0  1 â”‚          â”‚ 12  16  â”‚
â”‚ 6  7  8  9  10  â”‚   *    â”‚ 0  1  0 â”‚    =     â”‚ 22  26  â”‚
â”‚ 11 12 13 14 15  â”‚        â”‚ 1  0  1 â”‚          â”‚ ...     â”‚
â”‚ 16 17 18 19 20  â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ 21 22 23 24 25  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Calculation for top-left output:
(1Ã—1) + (2Ã—0) + (3Ã—1) + (6Ã—0) + (7Ã—1) + (8Ã—0) + (11Ã—1) + (12Ã—0) + (13Ã—1)
= 1 + 0 + 3 + 0 + 7 + 0 + 11 + 0 + 13 = 35
```

### Key Properties of Convolution

1. **Sparse Connectivity**: Each output neuron connects to only a small region of the input
2. **Parameter Sharing**: The same filter weights are used across the entire image
3. **Equivariance to Translation**: If the input shifts, the output shifts by the same amount

---

## Feature Hierarchies

One of the most powerful aspects of CNNs is their ability to learn hierarchical features automatically.

### Layer-by-Layer Feature Learning

```
Layer 1 (Early):     Layer 2 (Middle):    Layer 3 (Deep):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Edges     â”‚      â”‚   Textures  â”‚      â”‚   Objects   â”‚
â”‚   Corners   â”‚  â†’   â”‚   Patterns  â”‚  â†’   â”‚   Parts     â”‚
â”‚   Gradients â”‚      â”‚   Shapes    â”‚      â”‚   Faces     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Simple              Combinations         Complex
   Features            of Simple            Concepts
```

### What Each Layer Learns

| Layer Depth | Features Detected | Example |
|-------------|-------------------|---------|
| Layer 1 | Edges, colors, gradients | Horizontal/vertical lines |
| Layer 2 | Textures, simple shapes | Corners, circles |
| Layer 3 | Object parts | Eyes, wheels, windows |
| Layer 4+ | Whole objects, scenes | Faces, cars, buildings |

This hierarchical learning happens automatically through backpropagation â€” the network discovers which features are useful for the task.

---

## CNN Architecture Overview

A typical CNN consists of two main parts:

### 1. Feature Extraction (Convolutional Base)

```
Input â†’ [Conv â†’ ReLU â†’ Pool] Ã— N â†’ Feature Maps
```

- **Convolutional layers**: Extract features using learnable filters
- **Activation (ReLU)**: Introduce non-linearity
- **Pooling layers**: Reduce spatial dimensions, add invariance

### 2. Classification (Fully Connected Head)

```
Feature Maps â†’ Flatten â†’ [Dense â†’ ReLU] Ã— M â†’ Output
```

- **Flatten**: Convert 2D feature maps to 1D vector
- **Dense layers**: Learn to classify based on extracted features
- **Output layer**: Produce final predictions (softmax for classification)

### Complete Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONVOLUTIONAL BASE                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Conv   â”‚   â”‚ Conv   â”‚   â”‚ Conv   â”‚   â”‚ Conv   â”‚          â”‚
â”‚  â”‚ 32     â”‚ â†’ â”‚ 64     â”‚ â†’ â”‚ 128    â”‚ â†’ â”‚ 256    â”‚          â”‚
â”‚  â”‚ filtersâ”‚   â”‚ filtersâ”‚   â”‚ filtersâ”‚   â”‚ filtersâ”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚      â†“            â†“            â†“            â†“                â”‚
â”‚   Pool 2Ã—2    Pool 2Ã—2    Pool 2Ã—2    Pool 2Ã—2              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLASSIFICATION HEAD                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚Flatten â”‚ â†’ â”‚Dense   â”‚ â†’ â”‚Dense   â”‚ â†’ Predictions         â”‚
â”‚  â”‚        â”‚   â”‚512     â”‚   â”‚10      â”‚   (Softmax)           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Receptive Field

The **receptive field** is the region of the input image that influences a particular neuron's output.

### How Receptive Field Grows

```
Layer 1: 3Ã—3 receptive field (direct from kernel)
Layer 2: 5Ã—5 receptive field (sees through layer 1)
Layer 3: 7Ã—7 receptive field (sees through layers 1 and 2)
...
Deep layers: Can "see" the entire image
```

### Why Receptive Field Matters

- **Early layers**: Small receptive field â†’ detect local features (edges)
- **Deep layers**: Large receptive field â†’ detect global features (objects)
- **Design consideration**: Deeper networks or larger kernels increase receptive field

---

## Channels and Feature Maps

### Input Channels

- **Grayscale image**: 1 channel (height Ã— width Ã— 1)
- **RGB image**: 3 channels (height Ã— width Ã— 3)

### Feature Maps (Output Channels)

Each convolutional layer produces multiple feature maps, one per filter:

```
Input: 224Ã—224Ã—3 (RGB image)
       â†“
Conv Layer: 32 filters of size 3Ã—3
       â†“
Output: 222Ã—222Ã—32 (32 feature maps)
```

Each feature map represents a different learned feature (edge detector, color blob detector, etc.).

---

## Key Terminology

| Term | Definition |
|------|------------|
| **Kernel/Filter** | Small matrix of learnable weights that slides across input |
| **Feature Map** | Output of applying a filter to the input |
| **Stride** | Step size when sliding the filter |
| **Padding** | Adding zeros around input to control output size |
| **Receptive Field** | Region of input that affects a neuron's output |
| **Channel** | Depth dimension (3 for RGB, N for N filters) |

---

## Summary

CNNs revolutionized computer vision by:

1. **Preserving spatial structure** through local connectivity
2. **Reducing parameters** through weight sharing
3. **Learning hierarchical features** automatically
4. **Achieving translation invariance** through convolution and pooling

These properties make CNNs the go-to architecture for any task involving images, from classification to object detection to image generation.

---

*Next: [02-Kernels-and-Filters.md](02-Kernels-and-Filters.md) â€” Learn how filters detect features*
