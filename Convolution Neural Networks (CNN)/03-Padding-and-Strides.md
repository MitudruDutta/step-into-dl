# ğŸ“ Padding and Strides

## Overview

**Padding** and **stride** are two crucial hyperparameters that control the spatial dimensions of CNN outputs. Understanding them is essential for designing CNN architectures.

---

## Stride

### What is Stride?

**Stride** determines how many pixels the filter moves at each step. A stride of 1 means the filter moves one pixel at a time; a stride of 2 means it skips every other pixel.

### Stride Visualization

```
Stride = 1 (Default):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â–  â–  â–  â–¡ â–¡   â”‚  Step 1: Position (0,0)
â”‚ â–  â–  â–  â–¡ â–¡   â”‚
â”‚ â–  â–  â–  â–¡ â–¡   â”‚
â”‚ â–¡ â–¡ â–¡ â–¡ â–¡   â”‚
â”‚ â–¡ â–¡ â–¡ â–¡ â–¡   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â–¡ â–  â–  â–  â–¡   â”‚  Step 2: Position (0,1)
â”‚ â–¡ â–  â–  â–  â–¡   â”‚
â”‚ â–¡ â–  â–  â–  â–¡   â”‚
â”‚ â–¡ â–¡ â–¡ â–¡ â–¡   â”‚
â”‚ â–¡ â–¡ â–¡ â–¡ â–¡   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Stride = 2:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â–  â–  â–  â–¡ â–¡   â”‚  Step 1: Position (0,0)
â”‚ â–  â–  â–  â–¡ â–¡   â”‚
â”‚ â–  â–  â–  â–¡ â–¡   â”‚
â”‚ â–¡ â–¡ â–¡ â–¡ â–¡   â”‚
â”‚ â–¡ â–¡ â–¡ â–¡ â–¡   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â–¡ â–¡ â–  â–  â–    â”‚  Step 2: Position (0,2) â€” skipped (0,1)
â”‚ â–¡ â–¡ â–  â–  â–    â”‚
â”‚ â–¡ â–¡ â–  â–  â–    â”‚
â”‚ â–¡ â–¡ â–¡ â–¡ â–¡   â”‚
â”‚ â–¡ â–¡ â–¡ â–¡ â–¡   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Effect of Stride on Output Size

```
Input: 6Ã—6, Kernel: 3Ã—3

Stride 1: Output = 4Ã—4 (moves 4 times in each direction)
Stride 2: Output = 2Ã—2 (moves 2 times in each direction)
Stride 3: Output = 2Ã—2 (moves 2 times, with some overlap lost)
```

### When to Use Different Strides

| Stride | Use Case |
|--------|----------|
| **1** | Default, preserves spatial information |
| **2** | Downsampling (alternative to pooling) |
| **>2** | Aggressive downsampling, rarely used |

---

## Padding

### What is Padding?

**Padding** adds extra pixels (usually zeros) around the border of the input image before convolution. This controls the output size and preserves edge information.

### Types of Padding

**No Padding (Valid)**
```
Input: 5Ã—5, Kernel: 3Ã—3
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â–¡ â–¡ â–¡ â–¡ â–¡   â”‚
â”‚ â–¡ â–¡ â–¡ â–¡ â–¡   â”‚
â”‚ â–¡ â–¡ â–¡ â–¡ â–¡   â”‚
â”‚ â–¡ â–¡ â–¡ â–¡ â–¡   â”‚
â”‚ â–¡ â–¡ â–¡ â–¡ â–¡   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Output: 3Ã—3 (shrinks)
```

**Same Padding (Zero Padding)**
```
Input: 5Ã—5, Kernel: 3Ã—3, Padding: 1
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 0 0 0 0 0 0 0   â”‚  â† Added zeros
â”‚ 0 â–¡ â–¡ â–¡ â–¡ â–¡ 0   â”‚
â”‚ 0 â–¡ â–¡ â–¡ â–¡ â–¡ 0   â”‚
â”‚ 0 â–¡ â–¡ â–¡ â–¡ â–¡ 0   â”‚
â”‚ 0 â–¡ â–¡ â–¡ â–¡ â–¡ 0   â”‚
â”‚ 0 â–¡ â–¡ â–¡ â–¡ â–¡ 0   â”‚
â”‚ 0 0 0 0 0 0 0   â”‚  â† Added zeros
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Output: 5Ã—5 (same as input)
```

### Padding Modes

| Mode | Description | Use Case |
|------|-------------|----------|
| **Zero (Constant)** | Pad with zeros | Most common |
| **Reflect** | Mirror the edge pixels | Avoid edge artifacts |
| **Replicate** | Repeat edge pixels | Natural images |
| **Circular** | Wrap around | Periodic signals |

---

## Output Size Formula

The fundamental formula for calculating output dimensions:

```
Output Size = âŒŠ(Input Size - Kernel Size + 2Ã—Padding) / StrideâŒ‹ + 1
```

### Examples

**Example 1: No Padding, Stride 1**
```
Input: 32Ã—32
Kernel: 3Ã—3
Padding: 0
Stride: 1

Output = (32 - 3 + 0) / 1 + 1 = 30Ã—30
```

**Example 2: Same Padding, Stride 1**
```
Input: 32Ã—32
Kernel: 3Ã—3
Padding: 1
Stride: 1

Output = (32 - 3 + 2) / 1 + 1 = 32Ã—32 (same!)
```

**Example 3: Stride 2 Downsampling**
```
Input: 32Ã—32
Kernel: 3Ã—3
Padding: 1
Stride: 2

Output = (32 - 3 + 2) / 2 + 1 = 16Ã—16 (halved!)
```

**Example 4: 7Ã—7 Kernel (Common in First Layer)**
```
Input: 224Ã—224
Kernel: 7Ã—7
Padding: 3
Stride: 2

Output = (224 - 7 + 6) / 2 + 1 = 112Ã—112
```

---

## Calculating Padding for "Same" Output

To keep output size equal to input size (with stride 1):

```
Padding = (Kernel Size - 1) / 2

For 3Ã—3 kernel: Padding = (3-1)/2 = 1
For 5Ã—5 kernel: Padding = (5-1)/2 = 2
For 7Ã—7 kernel: Padding = (7-1)/2 = 3
```

Note: This only works for odd kernel sizes. Even kernels require asymmetric padding.

---

## Common Configurations

### Configuration 1: Preserve Dimensions
```
Kernel: 3Ã—3
Padding: 1
Stride: 1
Result: Output size = Input size
```

### Configuration 2: Halve Dimensions
```
Kernel: 3Ã—3
Padding: 1
Stride: 2
Result: Output size = Input size / 2
```

### Configuration 3: Aggressive Downsampling (First Layer)
```
Kernel: 7Ã—7
Padding: 3
Stride: 2
Result: Output size = Input size / 2
```

---

## Why Padding Matters

### Problem: Shrinking Feature Maps

Without padding, each convolution shrinks the spatial dimensions:

```
Layer 1: 32Ã—32 â†’ 30Ã—30 (3Ã—3 conv)
Layer 2: 30Ã—30 â†’ 28Ã—28 (3Ã—3 conv)
Layer 3: 28Ã—28 â†’ 26Ã—26 (3Ã—3 conv)
...
After 15 layers: 2Ã—2 (too small!)
```

### Problem: Edge Information Loss

Without padding, edge pixels contribute to fewer output values:

```
Corner pixel: Used in 1 convolution
Edge pixel: Used in 3 convolutions  
Center pixel: Used in 9 convolutions (for 3Ã—3 kernel)

Edge information is underrepresented!
```

### Solution: Use Padding

With padding=1 for 3Ã—3 kernels:
- Spatial dimensions preserved
- All pixels contribute equally
- Can build deeper networks

---

## Stride vs Pooling for Downsampling

Both can reduce spatial dimensions, but they work differently:

### Strided Convolution
```
Pros:
- Learnable downsampling
- Fewer layers needed
- Can capture more information

Cons:
- May miss fine details
- Aliasing possible
```

### Pooling
```
Pros:
- Provides translation invariance
- No additional parameters
- Well-understood behavior

Cons:
- Fixed operation (not learned)
- May lose spatial information
```

### Modern Trend

Many modern architectures (ResNet, EfficientNet) prefer strided convolutions over pooling for downsampling, except for the final global pooling.

---

## Practical Guidelines

### For Feature Extraction Layers
```
Use: kernel=3Ã—3, padding=1, stride=1
Result: Preserves spatial dimensions
When to downsample: Use stride=2 or pooling
```

### For First Layer (Large Images)
```
Use: kernel=7Ã—7, padding=3, stride=2
Result: Quickly reduces dimensions
Why: 224Ã—224 â†’ 112Ã—112 in one layer
```

### For Bottleneck Layers
```
Use: kernel=1Ã—1, padding=0, stride=1
Result: Changes channels, not spatial size
Why: Efficient channel manipulation
```

---

## Dimension Tracking Example

Let's trace dimensions through a simple CNN:

```
Input: 224Ã—224Ã—3

Conv1: 7Ã—7, padding=3, stride=2, 64 filters
  â†’ (224-7+6)/2+1 = 112Ã—112Ã—64

Pool1: 3Ã—3, stride=2
  â†’ 56Ã—56Ã—64

Conv2: 3Ã—3, padding=1, stride=1, 128 filters
  â†’ 56Ã—56Ã—128

Pool2: 2Ã—2, stride=2
  â†’ 28Ã—28Ã—128

Conv3: 3Ã—3, padding=1, stride=1, 256 filters
  â†’ 28Ã—28Ã—256

Pool3: 2Ã—2, stride=2
  â†’ 14Ã—14Ã—256

Conv4: 3Ã—3, padding=1, stride=1, 512 filters
  â†’ 14Ã—14Ã—512

Global Avg Pool:
  â†’ 1Ã—1Ã—512

Flatten:
  â†’ 512

Dense â†’ Output
```

---

## Summary

| Concept | Purpose | Common Values |
|---------|---------|---------------|
| **Stride** | Control step size, downsampling | 1 (preserve), 2 (halve) |
| **Padding** | Control output size, preserve edges | 0 (valid), k//2 (same) |

Key formulas:
- Output = (Input - Kernel + 2Ã—Padding) / Stride + 1
- Same padding = (Kernel - 1) / 2

---

*Next: [04-Pooling-Layers.md](04-Pooling-Layers.md) â€” Downsampling and invariance*
