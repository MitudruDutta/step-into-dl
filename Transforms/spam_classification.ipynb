{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# ðŸ“§ Spam Classification with BERT\n",
    "\n",
    "This notebook demonstrates a complete **transfer learning pipeline** using BERT for text classification. We'll fine-tune a pre-trained BERT model to classify SMS messages as spam or ham (not spam).\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "```text\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    TRANSFER LEARNING PIPELINE                  â”‚\n",
    "â”‚                                                                â”‚\n",
    "â”‚  1. Load Data â†’ 2. Preprocess â†’ 3. Tokenize â†’ 4. Create Model  â”‚\n",
    "â”‚                                                                â”‚\n",
    "â”‚  5. Train (freeze BERT) â†’ 6. Evaluate â†’ 7. Predict             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|:--------|:------------|\n",
    "| **Transfer Learning** | Use pre-trained BERT, only train classifier head |\n",
    "| **Feature Extraction** | Freeze BERT weights, extract embeddings |\n",
    "| **[CLS] Token** | Use the first token's embedding for classification |\n",
    "| **Binary Classification** | Spam (1) vs Ham (0) |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-section",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "device-section",
   "metadata": {},
   "source": [
    "### Check GPU Availability\n",
    "\n",
    "BERT is computationally intensive, so we'll use GPU if available for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "device",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-section",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Load and Explore the Dataset\n",
    "\n",
    "We're using the **SMS Spam Collection** dataset, which contains labeled SMS messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "label-encode",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "\n",
    "Convert text labels to numeric values:\n",
    "- `ham` â†’ `0` (legitimate message)\n",
    "- `spam` â†’ `1` (spam message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encode-labels",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Category = df.Category.map({'ham':0, 'spam':1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "class-dist",
   "metadata": {},
   "source": [
    "### Class Distribution\n",
    "\n",
    "Let's check the balance of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "value-counts",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imbalance-explain",
   "metadata": {},
   "source": [
    "**âš ï¸ Class Imbalance Detected!**\n",
    "\n",
    "```text\n",
    "Ham:  4825 (87%)\n",
    "Spam:  747 (13%)\n",
    "```\n",
    "\n",
    "The dataset is heavily imbalanced. To address this, we'll:\n",
    "1. Keep all spam messages (747)\n",
    "2. Randomly sample 1000 ham messages\n",
    "\n",
    "This creates a more balanced dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filter-spam",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = df[df.Category == 1]\n",
    "df_spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample-ham",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham_small = df[df.Category == 0].sample(n=1000, random_state=42)\n",
    "df_ham_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concat-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = pd.concat([df_spam, df_ham_small])\n",
    "df_small.Category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-section",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Train/Test Split\n",
    "\n",
    "Split the data into training (80%) and validation (20%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-test-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_small.Message,\n",
    "    df_small.Category,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-dist",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-dist",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tokenize-section",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Tokenization\n",
    "\n",
    "We need to convert text into the format BERT expects:\n",
    "\n",
    "```text\n",
    "Input Text: \"Click here to win!\"\n",
    "         â†“\n",
    "    Tokenizer\n",
    "         â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ input_ids:      [101, 11562, 2182, ...]    â”‚ â† Token IDs\n",
    "â”‚ attention_mask: [1, 1, 1, 1, 0, 0, ...]    â”‚ â† 1=real, 0=padding\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Key Parameters:**\n",
    "- `max_length=128`: Truncate/pad all sequences to 128 tokens\n",
    "- `padding='max_length'`: Pad shorter sequences\n",
    "- `truncation=True`: Truncate longer sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tokenizer-func",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_function(texts, labels):\n",
    "    encodings = tokenizer(texts, padding='max_length', max_length=128, truncation=True, return_tensors='pt')\n",
    "    return encodings['input_ids'], encodings['attention_mask'], torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "# Example\n",
    "tokenize_function(['Click here, Hurry', 'Let\\'s have lunch tomorrow'], [1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tokenize-all",
   "metadata": {},
   "source": [
    "### Tokenize All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tokenize-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids, train_attention_mask, train_labels = tokenize_function(X_train.values.tolist(), y_train.values.tolist())\n",
    "val_input_ids, val_attention_mask, val_labels = tokenize_function(X_test.values.tolist(), y_test.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-section",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Create PyTorch DataLoaders\n",
    "\n",
    "DataLoaders handle batching, shuffling, and efficient data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-datasets",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(train_input_ids, train_attention_mask, train_labels)\n",
    "val_dataset = torch.utils.data.TensorDataset(val_input_ids, val_attention_mask, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-loaders",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-section",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Build the Classification Model\n",
    "\n",
    "Our model architecture:\n",
    "\n",
    "```text\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    SPAM CLASSIFIER                        â”‚\n",
    "â”‚                                                           â”‚\n",
    "â”‚   Input: [CLS] tokenâ‚ tokenâ‚‚ ... tokenâ‚™ [SEP] [PAD] ...   â”‚\n",
    "â”‚              â†“                                            â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚\n",
    "â”‚   â”‚           BERT (FROZEN)                         â”‚     â”‚\n",
    "â”‚   â”‚   12 Transformer Encoder Layers                 â”‚     â”‚\n",
    "â”‚   â”‚   Pre-trained weights (110M parameters)         â”‚     â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚\n",
    "â”‚              â†“ (extract [CLS] token embedding)            â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚\n",
    "â”‚   â”‚        CLASSIFIER HEAD (TRAINABLE)              â”‚     â”‚\n",
    "â”‚   â”‚   Linear(768 â†’ 256) â†’ ReLU â†’ Dropout(0.3)       â”‚     â”‚\n",
    "â”‚   â”‚   Linear(256 â†’ 1) â†’ Sigmoid                     â”‚     â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚\n",
    "â”‚              â†“                                            â”‚\n",
    "â”‚   Output: Spam Probability (0.0 to 1.0)                   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Why freeze BERT?**\n",
    "- BERT is already trained on massive data\n",
    "- Training only the classifier head is faster\n",
    "- Prevents overfitting on small datasets\n",
    "- Reduces memory requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "\n",
    "        # Freeze BERT parameters (transfer learning)\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get BERT output\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract [CLS] token embedding (position 0)\n",
    "        sentence_embedding = bert_output.last_hidden_state[:,0,:]\n",
    "        \n",
    "        # Pass through classifier\n",
    "        return self.classifier(sentence_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "init-section",
   "metadata": {},
   "source": [
    "### Initialize Model, Optimizer, and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "init-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentClassifier()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy for binary classification\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-section",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Training Loop\n",
    "\n",
    "We'll train for 2 epochs (since BERT features are already good, we don't need many).\n",
    "\n",
    "**Training Process:**\n",
    "1. Forward pass through model\n",
    "2. Calculate loss (BCE)\n",
    "3. Backward pass (compute gradients)\n",
    "4. Update classifier weights (BERT stays frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch, (input_ids, attention_mask, labels) in enumerate(train_loader):\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask).squeeze(dim=-1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Batch: {batch}, Epoch: {epoch}, Loss:  {loss.item():0.2f}\")\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-section",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Evaluation\n",
    "\n",
    "Evaluate the model on the validation set to measure accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_val_loss = 0\n",
    "correct_predictions = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input_ids, attention_mask, labels in val_loader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask).squeeze(dim=-1)\n",
    "        loss = criterion(outputs, labels.view_as(outputs))\n",
    "        total_val_loss += loss.item()\n",
    "\n",
    "        preds = (outputs > 0.5).float()\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "avg_val_loss = total_val_loss / len(val_loader)\n",
    "val_accuracy = correct_predictions.double() / len(val_dataset)\n",
    "print(f'Validation Loss: {avg_val_loss}, Validation Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "predict-section",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Inference on New Messages\n",
    "\n",
    "Let's create a function to classify new messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "predict-func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_message(text, model, tokenizer, device, max_length=128):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask).squeeze(dim=-1)\n",
    "        prob = output.item()\n",
    "        label = 'spam' if prob > 0.5 else 'ham'\n",
    "        return label, prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-predict",
   "metadata": {},
   "source": [
    "### Test with Sample Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-spam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a spam message\n",
    "sample_text = \"WINNER! You've won a luxury holiday! Call now to claim.\"\n",
    "label, confidence = predict_message(sample_text, model, tokenizer, device)\n",
    "print(f\"Text: {sample_text}\\nPrediction: {label} (Confidence: {confidence:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-ham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a ham message\n",
    "sample_text = \"Hey, are we still meeting for lunch tomorrow?\"\n",
    "label, confidence = predict_message(sample_text, model, tokenizer, device)\n",
    "print(f\"Text: {sample_text}\\nPrediction: {label} (Confidence: {confidence:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“š Key Takeaways\n",
    "\n",
    "| Concept | Description |\n",
    "|:--------|:------------|\n",
    "| **Transfer Learning** | Use pre-trained BERT as feature extractor |\n",
    "| **Frozen Weights** | Don't update BERT parameters during training |\n",
    "| **[CLS] Token** | First token captures sentence-level meaning |\n",
    "| **Classifier Head** | Small trainable network on top of BERT |\n",
    "| **BCE Loss** | Binary Cross Entropy for binary classification |\n",
    "| **Fast Training** | Only 2 epochs needed with pre-trained features |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Possible Improvements\n",
    "\n",
    "1. **Fine-tune BERT**: Unfreeze some layers for better performance\n",
    "2. **Use BertForSequenceClassification**: Hugging Face's pre-built classifier\n",
    "3. **Add more data**: Use the full dataset with class weighting\n",
    "4. **Try different models**: DistilBERT for faster inference, RoBERTa for better performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
