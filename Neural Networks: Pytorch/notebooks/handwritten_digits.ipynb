{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db22f6ef",
   "metadata": {},
   "source": [
    "# ðŸ”¢ Handwritten Digit Classification with PyTorch\n",
    "\n",
    "This notebook builds a complete neural network to classify handwritten digits (0-9) using the MNIST dataset.\n",
    "\n",
    "## What You'll Learn\n",
    "- Loading and preprocessing MNIST data\n",
    "- Building a neural network with `nn.Module`\n",
    "- Training loop implementation\n",
    "- Model evaluation and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ea5d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6e86d5",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We apply two transforms:\n",
    "1. **ToTensor()**: Converts PIL image to tensor and scales pixels to [0, 1]\n",
    "2. **Normalize((0.5), (0.5))**: Normalizes to mean=0.5, std=0.5, resulting in values in [-1, 1]\n",
    "\n",
    "Normalization helps the model train faster and more stably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0124e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a2bee",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "\n",
    "MNIST contains:\n",
    "- 60,000 training images\n",
    "- 10,000 test images\n",
    "- 10 classes (digits 0-9)\n",
    "- Each image is 28Ã—28 grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae8738",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a79d40",
   "metadata": {},
   "source": [
    "## Creating DataLoaders\n",
    "\n",
    "- **batch_size=64**: Process 64 images at a time\n",
    "- **shuffle=True** for training: Randomize order each epoch\n",
    "- **shuffle=False** for testing: Keep order consistent for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b066d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7da2527",
   "metadata": {},
   "source": [
    "## Visualizing a Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb1722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray')\n",
    "plt.title(f\"Label: {labels[0].item()}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3271e4c9",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "Our neural network:\n",
    "1. **Flatten**: Convert 28Ã—28 image to 784-element vector\n",
    "2. **Linear(784, 128)**: First hidden layer\n",
    "3. **ReLU**: Activation function\n",
    "4. **Linear(128, 64)**: Second hidden layer\n",
    "5. **ReLU**: Activation function\n",
    "6. **Linear(64, 10)**: Output layer (10 classes, no softmax!)\n",
    "\n",
    "**Note**: We don't apply softmax because `CrossEntropyLoss` includes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f0b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitsClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(784, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203547ad",
   "metadata": {},
   "source": [
    "## Setting Up Training\n",
    "\n",
    "- **Model**: Our DigitsClassifier\n",
    "- **Optimizer**: Adam with learning rate 0.001\n",
    "- **Loss**: CrossEntropyLoss (for multi-class classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a248f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DigitsClassifier()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ffe7f1",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "For each epoch:\n",
    "1. Iterate through batches\n",
    "2. Forward pass: Get predictions\n",
    "3. Calculate loss\n",
    "4. Backward pass: Compute gradients\n",
    "5. Update weights\n",
    "\n",
    "**Important**: Call `optimizer.zero_grad()` before `loss.backward()` to clear old gradients!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Track loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a7b76",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "**Important steps for evaluation:**\n",
    "1. `model.eval()`: Set model to evaluation mode (disables dropout, etc.)\n",
    "2. `torch.no_grad()`: Disable gradient computation (saves memory)\n",
    "3. `torch.max(outputs, 1)`: Get predicted class (highest score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8173a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on test set: {accuracy:.2f}%')\n",
    "print(f'Correct: {correct} / {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2ff718",
   "metadata": {},
   "source": [
    "## Detailed Classification Report\n",
    "\n",
    "Using sklearn to get precision, recall, and F1-score for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e3e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "all_predicted = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_predicted.extend(predicted.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f357ee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(all_labels, all_predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e519fb",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "The confusion matrix shows:\n",
    "- Diagonal: Correct predictions\n",
    "- Off-diagonal: Misclassifications (row = actual, column = predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7013629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_predicted)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=range(10), yticklabels=range(10))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c1ed5f",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Data preprocessing** (normalization) helps training stability\n",
    "2. **nn.Sequential** makes it easy to chain layers\n",
    "3. **CrossEntropyLoss** includes softmax - don't apply it twice!\n",
    "4. **model.eval()** and **torch.no_grad()** are essential for evaluation\n",
    "5. **Confusion matrix** reveals which digits are commonly confused"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
