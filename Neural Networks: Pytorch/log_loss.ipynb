{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fcc23fc",
   "metadata": {},
   "source": [
    "# üìâ Loss Functions: MSE vs Binary Cross Entropy\n",
    "\n",
    "This notebook demonstrates why **Binary Cross Entropy (BCE)** is preferred over **Mean Squared Error (MSE)** for classification tasks.\n",
    "\n",
    "## Key Concepts\n",
    "- **MSE**: Measures squared difference between prediction and target\n",
    "- **BCE**: Measures the \"surprise\" of a prediction, heavily penalizing confident wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0ca513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3db99b9",
   "metadata": {},
   "source": [
    "## MSE Loss Example\n",
    "\n",
    "MSE calculates: `(prediction - target)¬≤`\n",
    "\n",
    "Here we predict 0.1 when the target is 1.0 (a wrong prediction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0e850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "y_pred = torch.tensor([0.1])\n",
    "y_true = torch.tensor([1.0], dtype=torch.float32)\n",
    "\n",
    "loss = criterion(y_pred, y_true)\n",
    "print(f\"MSE Loss: {loss.item(): .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b6f29f",
   "metadata": {},
   "source": [
    "## Binary Cross Entropy Loss\n",
    "\n",
    "BCE formula: `-[y √ó log(p) + (1-y) √ó log(1-p)]`\n",
    "\n",
    "### Example 1: Confident Wrong Prediction\n",
    "Predicting 0.9 (90% confident it's class 1) when target is 0.\n",
    "\n",
    "**Notice how BCE gives a much higher loss (2.30) compared to MSE for a similar wrong prediction!**\n",
    "\n",
    "This is the key advantage of BCE: it heavily penalizes confident wrong predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab3e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "y_pred = torch.tensor([0.9])\n",
    "y_true = torch.tensor([0], dtype=torch.float32)\n",
    "\n",
    "loss = criterion(y_pred, y_true)\n",
    "print(f\"Binary Cross Entropy Loss: {loss.item(): .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37b9d65",
   "metadata": {},
   "source": [
    "### Example 2: Multiple Predictions\n",
    "\n",
    "BCE averages the loss across all samples:\n",
    "\n",
    "| Prediction | Target | Correct? |\n",
    "|------------|--------|----------|\n",
    "| 0.8 | 1 | ‚úÖ Yes |\n",
    "| 0.2 | 0 | ‚úÖ Yes |\n",
    "| 0.8 | 0 | ‚ùå No (confident wrong) |\n",
    "| 0.9 | 1 | ‚úÖ Yes |\n",
    "\n",
    "The third prediction (0.8 when target is 0) will contribute most to the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4df562",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "y_pred = torch.tensor([0.8, 0.2, 0.8, 0.9])\n",
    "y_true = torch.tensor([1, 0, 0, 1], dtype=torch.float32)\n",
    "\n",
    "loss = criterion(y_pred, y_true)\n",
    "print(f\"Binary Cross Entropy Loss: {loss.item(): .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18162ff9",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **MSE** is good for regression but creates non-convex loss surfaces for classification\n",
    "2. **BCE** creates smooth, convex loss surfaces ideal for binary classification\n",
    "3. BCE heavily penalizes confident wrong predictions, helping the model learn faster\n",
    "4. Always use BCE (or `BCEWithLogitsLoss`) for binary classification tasks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
