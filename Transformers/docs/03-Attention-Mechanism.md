# ğŸ¯ The Attention Mechanism: Focused Learning

The **Attention Mechanism** is the core innovation of the Transformer architecture. It allows the model to dynamically focus on relevant parts of the input when producing each output, enabling parallel processing and capturing long-range dependencies.

---

## The Core Intuition

Imagine translating "The cat sat on the mat" to French. When generating "chat" (cat), you focus on "cat." When generating "tapis" (mat), you shift focus to "mat." Attention automates this selective focus.

```text
English: "The  cat  sat  on  the  mat"
              â†“              â†“
           HIGH           HIGH
          attention      attention
              â†“              â†“
French:   "Le chat s'est assis sur le tapis"
```

---

## Self-Attention: Relating Tokens

Self-attention computes relationships between ALL input tokens simultaneously, capturing dependencies regardless of distance.

### The Three Components

| Component     | Symbol    | Description           | Intuition                  |
| :------------ | :-------- | :-------------------- | :------------------------- |
| **Query (Q)** | `Q = XWq` | What I'm looking for  | "What am I searching for?" |
| **Key (K)**   | `K = XWk` | What I contain        | "What do I represent?"     |
| **Value (V)** | `V = XWv` | My actual information | "What info do I carry?"    |

### The Attention Formula

```text
Attention(Q, K, V) = softmax(QKáµ€ / âˆšdâ‚–) Ã— V
```

### Step-by-Step Breakdown

```text
Step 1: Compute Similarity Scores
        QKáµ€ â†’ dot products between queries and keys

        "The"   "cat"   "sat"   "on"
   "The"  0.8    0.3     0.1    0.2
   "cat"  0.2    0.9     0.7    0.1
   "sat"  0.1    0.6     0.8    0.4
   "on"   0.2    0.1     0.3    0.9

Step 2: Scale
        Divide by âˆšdâ‚– to prevent extreme values

Step 3: Softmax
        Convert to probabilities (sum to 1)

        "The"   "cat"   "sat"   "on"
   "The" 0.45   0.25    0.15   0.15    = 1.0
   "cat" 0.15   0.40    0.35   0.10    = 1.0
   ...

Step 4: Weighted Sum
        Multiply by Values to get output
        Each token is now a weighted combination of all tokens
```

---

## Visualizing Attention

```text
Input: "The cat sat on the mat"

Attention weights for "sat":

Token:    The   cat   sat   on   the   mat
Weight:  0.05  0.35  0.30  0.05  0.05  0.20
              â–²â–²â–²              â–²â–²â–²
         subject peak      object peak

The verb "sat" strongly attends to:
  - "cat" (who is sitting)
  - "mat" (where sitting occurred)
```

### Attention Heatmap

```text
         The  cat  sat  on  the  mat
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
The â”‚ â–ˆâ–ˆâ–ˆ  â–‘â–‘â–‘  â–‘â–‘â–‘  â–‘â–‘â–‘  â–‘â–‘â–‘  â–‘â–‘â–‘  â”‚
cat â”‚ â–‘â–‘â–‘  â–ˆâ–ˆâ–ˆ  â–“â–“â–“  â–‘â–‘â–‘  â–‘â–‘â–‘  â–‘â–‘â–‘  â”‚
sat â”‚ â–‘â–‘â–‘  â–“â–“â–“  â–ˆâ–ˆâ–ˆ  â–‘â–‘â–‘  â–‘â–‘â–‘  â–“â–“â–‘  â”‚
on  â”‚ â–‘â–‘â–‘  â–‘â–‘â–‘  â–“â–“â–‘  â–ˆâ–ˆâ–ˆ  â–‘â–‘â–‘  â–“â–“â–“  â”‚
the â”‚ â–‘â–‘â–‘  â–‘â–‘â–‘  â–‘â–‘â–‘  â–‘â–‘â–‘  â–ˆâ–ˆâ–ˆ  â–‘â–“â–‘  â”‚
mat â”‚ â–‘â–‘â–‘  â–‘â–“â–‘  â–“â–“â–‘  â–“â–“â–“  â–‘â–“â–‘  â–ˆâ–ˆâ–ˆ  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Legend: â–ˆâ–ˆâ–ˆ = high attention, â–“â–“â–“ = medium, â–‘â–‘â–‘ = low
```

---

## Why Scale by âˆšdâ‚–?

```text
Problem without scaling:

When dâ‚– (dimension) is large (e.g., 64):
  dot product values become very large/small

  QKáµ€ might produce: [25.3, 2.1, -18.7, 31.2]

  softmax([25.3, 2.1, -18.7, 31.2])
  = [0.003, 0.000, 0.000, 0.997]  â† Almost one-hot!

  Gradients become tiny (vanishing gradient)

Solution - scale by âˆšdâ‚–:

  [25.3, 2.1, -18.7, 31.2] / âˆš64
  = [3.16, 0.26, -2.34, 3.90]

  softmax = [0.21, 0.11, 0.01, 0.47]  â† Smoother distribution!
```

---

## Self-Attention vs Traditional Approaches

### Compared to RNNs

```text
RNN Processing (Sequential):

  xâ‚ â†’ hâ‚ â†’ xâ‚‚ â†’ hâ‚‚ â†’ xâ‚ƒ â†’ hâ‚ƒ â†’ xâ‚„ â†’ hâ‚„
           â†‘         â†‘         â†‘
        Info from xâ‚ must pass through
        every intermediate step

  Distance from xâ‚ to xâ‚„: 3 steps
  Information degrades with distance

Self-Attention (Parallel):

       xâ‚ â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ xâ‚„
        â†‘                          â†‘
  Direct connection! No degradation

  Distance from any token to any other: 1 step
```

### Comparison Table

| Aspect              | RNN        | Self-Attention  |
| :------------------ | :--------- | :-------------- |
| **Max Path Length** | O(n)       | O(1)            |
| **Parallelization** | Sequential | Fully parallel  |
| **Long-range deps** | Difficult  | Easy            |
| **Computation**     | O(n)       | O(nÂ²) per layer |

---

## Implementation in PyTorch

### Basic Self-Attention

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class SelfAttention(nn.Module):
    def __init__(self, embed_dim):
        super().__init__()
        self.embed_dim = embed_dim

        # Linear projections for Q, K, V
        self.W_q = nn.Linear(embed_dim, embed_dim)
        self.W_k = nn.Linear(embed_dim, embed_dim)
        self.W_v = nn.Linear(embed_dim, embed_dim)

    def forward(self, x):
        # x shape: (batch, seq_len, embed_dim)

        Q = self.W_q(x)  # Queries
        K = self.W_k(x)  # Keys
        V = self.W_v(x)  # Values

        # Attention scores: QKáµ€ / âˆšdâ‚–
        d_k = self.embed_dim
        scores = torch.matmul(Q, K.transpose(-2, -1)) / (d_k ** 0.5)

        # Softmax to get attention weights
        attn_weights = F.softmax(scores, dim=-1)

        # Weighted sum of values
        output = torch.matmul(attn_weights, V)

        return output, attn_weights

# Example
attention = SelfAttention(embed_dim=64)
x = torch.randn(2, 10, 64)  # batch=2, seq_len=10
output, weights = attention(x)
print(f"Output shape: {output.shape}")  # (2, 10, 64)
print(f"Attention weights: {weights.shape}")  # (2, 10, 10)
```

### Masked Self-Attention (for Decoders)

```python
def create_causal_mask(seq_len):
    """Create mask to prevent attending to future tokens."""
    mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)
    mask = mask.masked_fill(mask == 1, float('-inf'))
    return mask

# Usage in attention:
# scores = scores + causal_mask
# attn_weights = F.softmax(scores, dim=-1)
```

---

## Attention Patterns

Different attention heads learn different patterns:

```text
HEAD 1: Syntactic relationships
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ "The cat that I saw ran"â”‚
â”‚   â†‘___________â†‘         â”‚
â”‚ subject-verb agreement  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

HEAD 2: Adjacent tokens
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ "The  cat  sat"         â”‚
â”‚   â†”    â†”               â”‚
â”‚ Neighboring attention   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

HEAD 3: Semantic relationships
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ "Paris is the capital"  â”‚
â”‚   â†‘____________â†‘        â”‚
â”‚ Paris-capital link      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Summary

| Concept              | Description                        |
| :------------------- | :--------------------------------- |
| **Query (Q)**        | What each token is searching for   |
| **Key (K)**          | What each token represents         |
| **Value (V)**        | The actual information to retrieve |
| **Attention Scores** | QKáµ€ measures similarity            |
| **Scaling**          | Divide by âˆšdâ‚– for stable gradients |
| **Softmax**          | Convert scores to probabilities    |
| **Output**           | Weighted sum of values             |

---

## What's Next?

A single attention head captures one type of relationship. To capture multiple patterns simultaneously:

â¡ï¸ **Next:** [Multi-Head Attention](04-Multi-Head-Attention.md)

---

_Self-attention is what replaced recurrence in Transformers. Its ability to directly connect any two positions regardless of distance revolutionized sequence modeling._
